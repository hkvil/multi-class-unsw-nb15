{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMbT5gY2JJ5ipaj3BxXDnVU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hkvil/multi-class-unsw-nb15/blob/main/19_1_(GPU).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install lightgbm --config-settings=cmake.define.USE_GPU=ON"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s8H87aBtKAn",
        "outputId": "014db2ad-6419-4df5-8556-938f9a65b574"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting lightgbm\n",
            "  Using cached lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.13.1)\n",
            "Using cached lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: lightgbm\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~cikit-learn (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed lightgbm-4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd"
      ],
      "metadata": {
        "id": "5q5MASb7wUWW"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext cudf.pandas\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
        "from sklearn.metrics import classification_report,roc_auc_score,average_precision_score\n",
        "from sklearn.preprocessing import LabelEncoder,label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.utils import class_weight\n",
        "import time\n",
        "import joblib\n",
        "import os\n",
        "import json\n",
        "\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cb"
      ],
      "metadata": {
        "id": "xMEqM0geXw0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58731d8b-1c19-4ceb-ddb4-e6d825f08b06"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cudf.pandas extension is already loaded. To reload it, use:\n",
            "  %reload_ext cudf.pandas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 28"
      ],
      "metadata": {
        "id": "ZgsXwotGXxo8"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpoGWy3Yuejp",
        "outputId": "e011e717-981e-4f92-b23b-3127857ad5fe"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cufile.log  data-test.csv  data-train.csv  rmm_log.txt  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"data-train.csv\")\n",
        "df_test  = pd.read_csv(\"data-test.csv\")\n",
        "\n",
        "df_train.drop(columns=['id','label'],inplace=True)\n",
        "df_test.drop(columns=['id','label',],inplace=True)\n",
        "cat_features = ['proto','service','state']\n",
        "\n",
        "combined_df = pd.concat([df_train, df_test], ignore_index=True)\n",
        "\n",
        "le = LabelEncoder()\n",
        "# Encode labels in column 'attack_cat'.\n",
        "combined_df['attack_cat']= le.fit_transform(combined_df['attack_cat'])\n",
        "\n",
        "n_train = len(df_train)\n",
        "\n",
        "df_train = combined_df.iloc[:n_train].reset_index(drop=True)\n",
        "df_test  = combined_df.iloc[n_train:].reset_index(drop=True)\n",
        "\n",
        "print(\"Training set shape:\", df_train.shape)\n",
        "print(\"Test set shape:\", df_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-0yCAnPX11W",
        "outputId": "57d2f773-f8f1-499d-fd56-4fcf2e2565ff"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (175341, 43)\n",
            "Test set shape: (82332, 43)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_adasyn(df_train):\n",
        "    X, y = df_train.drop(columns=['attack_cat']), df_train['attack_cat']\n",
        "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "    # Step 1: One Hot Encoding\n",
        "    encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
        "    X_encoded = encoder.fit_transform(X[categorical_cols])\n",
        "    X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
        "\n",
        "    # Step 2: Combine the encoded columns with the remaining columns\n",
        "    X_combined = pd.concat([X.drop(columns=categorical_cols).reset_index(drop=True), X_encoded_df], axis=1)\n",
        "    current_X, current_y = X_combined, y\n",
        "\n",
        "    # Step 3: Apply ADASYN (Oversample all class except majority)\n",
        "    adasyn = ADASYN(random_state=seed)\n",
        "    X_resampled, y_resampled = adasyn.fit_resample(current_X, current_y)\n",
        "\n",
        "    # Step 4: Revert One Hot Encoding\n",
        "    X_resampled_df = pd.DataFrame(X_resampled, columns=X_combined.columns)\n",
        "    original_categorical_df = encoder.inverse_transform(X_resampled_df[encoder.get_feature_names_out(categorical_cols)])\n",
        "    original_categorical_df = pd.DataFrame(original_categorical_df, columns=categorical_cols)\n",
        "\n",
        "    # Combine the reverted categorical columns back with the other columns\n",
        "    final_X = pd.concat([X_resampled_df.drop(columns=encoder.get_feature_names_out(categorical_cols)),\n",
        "                         original_categorical_df], axis=1)\n",
        "\n",
        "    # Ensure the final column order matches the original order\n",
        "    final_X = final_X[X.columns]\n",
        "\n",
        "    # Combine the features with the target column\n",
        "    df_resampled = pd.concat([final_X, y_resampled.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    return df_resampled\n",
        "\n",
        "def perform_rfe_cv(df_train, min_features_to_select):\n",
        "    X, y = df_train.drop(columns=['attack_cat']), df_train['attack_cat']\n",
        "    categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
        "    numeric_features = X.select_dtypes(include=['int64', 'float64'])\n",
        "    model = lgb.LGBMClassifier(random_state=seed,data_sample_strategy='goss',verbose = -1,device='gpu')\n",
        "    rfe = RFECV(model, min_features_to_select=min_features_to_select,n_jobs=-1,verbose=0,cv=2) #cv=1 for testing purpose\n",
        "    rfe.fit(numeric_features, y)\n",
        "    selected_numeric_features = rfe.get_feature_names_out()\n",
        "    selected_features = list(selected_numeric_features) + list(categorical_features)\n",
        "    return selected_features\n",
        "\n",
        "def compute_class_weights(y):\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
        "    class_weights_dict = {cls: weight for cls, weight in zip(np.unique(y), class_weights)}\n",
        "\n",
        "    return class_weights_dict\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, fitting_time):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)\n",
        "\n",
        "    # Get unique class labels\n",
        "    classes = model.classes_\n",
        "\n",
        "    # Binarize the true labels for multiclass evaluation\n",
        "    y_test_binarized = label_binarize(y_test, classes=classes)\n",
        "\n",
        "    # Classification Report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # PR AUC (One-vs-Rest)\n",
        "    pr_auc_per_class = []\n",
        "    for i in range(y_pred_proba.shape[1]):  # Iterate through each class\n",
        "        pr_auc = average_precision_score(y_test_binarized[:, i], y_pred_proba[:, i])\n",
        "        pr_auc_per_class.append(pr_auc)\n",
        "\n",
        "    # PR AUC Overall (macro average)\n",
        "    pr_auc_overall = average_precision_score(y_test_binarized, y_pred_proba, average='macro')\n",
        "\n",
        "    return {\n",
        "        'classification_report': report,\n",
        "        'pr_auc_per_class': pr_auc_per_class,\n",
        "        'pr_auc_overall': pr_auc_overall,\n",
        "        'fitting_time': fitting_time,\n",
        "    }\n",
        "\n",
        "\n",
        "def objectToCategory(df):\n",
        "    data = df.copy()  # To avoid modifying the original DataFrame\n",
        "    for col in data.select_dtypes(include=['object']).columns:\n",
        "        data[col] = pd.Categorical(data[col]).codes\n",
        "    return data\n",
        "\n",
        "\n",
        "def export_all_results(all_results):\n",
        "    # Ensure output directory exists\n",
        "    output_dir = 'output'\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Define the output file path\n",
        "    file_path = f'{output_dir}/all_scenarios_results.json'\n",
        "\n",
        "    # Write all results to a single JSON file\n",
        "    with open(file_path, 'w') as json_file:\n",
        "        json.dump(all_results, json_file, indent=4)\n",
        "    print(f\"All results have been exported to {file_path}\")\n",
        "\n",
        "def run_scenario(scenario, df_train, df_test,selected_features ,df_train_adasyn,class_weights):\n",
        "\n",
        "    df_train = objectToCategory(df_train)\n",
        "    df_test = objectToCategory(df_test)\n",
        "    df_train_adasyn = objectToCategory(df_train_adasyn)\n",
        "\n",
        "\n",
        "    X_train, y_train = df_train.drop(columns=['attack_cat']), df_train['attack_cat']\n",
        "    X_test, y_test = df_test.drop(columns=['attack_cat']), df_test['attack_cat']\n",
        "\n",
        "\n",
        "    if 'ADASYN' in scenario:\n",
        "        X_train, y_train = df_train_adasyn.drop(columns=['attack_cat']), df_train_adasyn['attack_cat']\n",
        "\n",
        "    if 'RFE-CV' in scenario:\n",
        "        X_train = X_train[selected_features]\n",
        "        X_test = X_test[selected_features]\n",
        "\n",
        "    if 'CLASS WEIGHT' not in scenario:\n",
        "        class_weights = None\n",
        "\n",
        "\n",
        "    models = {\n",
        "        'LightGBM': lgb.LGBMClassifier(\n",
        "            random_state=seed,\n",
        "            objective='multiclass',\n",
        "            n_estimators=1000,\n",
        "            learning_rate=0.1,\n",
        "            class_weight=class_weights,\n",
        "            data_sample_strategy='goss',\n",
        "            verbose=-1,\n",
        "            device=\"gpu\"\n",
        "        ),\n",
        "        'XGBoost': xgb.XGBClassifier(\n",
        "            random_state=seed,\n",
        "            n_estimators=100,\n",
        "            learning_rate=0.1,\n",
        "            enable_categorical=True,\n",
        "            tree_method=\"approx\",\n",
        "            device=\"cuda\"\n",
        "        ),\n",
        "        'CatBoost': cb.CatBoostClassifier(\n",
        "            random_seed=seed,\n",
        "            n_estimators=100,\n",
        "            learning_rate=0.1,\n",
        "            class_weights=class_weights,\n",
        "            verbose=0,\n",
        "            cat_features=list(cat_features),\n",
        "            task_type=\"GPU\"\n",
        "        )\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        if model_name == 'XGBoost':\n",
        "            if 'CLASS WEIGHT' in scenario:\n",
        "                class_weights_xgb = class_weight.compute_sample_weight(\n",
        "                class_weight=class_weights,\n",
        "                y=y_train)\n",
        "                start_time = time.time()\n",
        "                model.fit(X_train, y_train,sample_weight=class_weights_xgb)\n",
        "                fitting_time = time.time() - start_time\n",
        "                results[model_name] = evaluate_model(model, X_test, y_test, fitting_time)\n",
        "            else:\n",
        "                start_time = time.time()\n",
        "                model.fit(X_train, y_train)\n",
        "                fitting_time = time.time() - start_time\n",
        "                results[model_name] = evaluate_model(model, X_test, y_test, fitting_time)\n",
        "        else:\n",
        "            start_time = time.time()\n",
        "            model.fit(X_train, y_train)\n",
        "            fitting_time = time.time() - start_time\n",
        "            results[model_name] = evaluate_model(model, X_test, y_test, fitting_time)\n",
        "\n",
        "\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "mmvRaJ-mX7Pr"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = perform_rfe_cv(df_train,10)\n",
        "class_weights = compute_class_weights(df_train['attack_cat'])\n",
        "df_train_adasyn = apply_adasyn(df_train)"
      ],
      "metadata": {
        "id": "dpH2IGMNX7z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print current time\n",
        "\n",
        "import time\n",
        "\n",
        "# ... (Your existing code)\n",
        "\n",
        "def print_current_time():\n",
        "    current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
        "    print(f\"Current time: {current_time}\")\n",
        "\n",
        "\n",
        "# Example usage (call the function wherever you need to print the time)\n",
        "print_current_time()\n",
        "#1038\n",
        "# ... (Rest of your existing code)"
      ],
      "metadata": {
        "id": "XFYjUTmLpA9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scenarios = [\n",
        "     [],\n",
        "    ['RFE-CV'],\n",
        "    ['ADASYN'],\n",
        "    ['CLASS WEIGHT'],\n",
        "    ['RFE-CV', 'ADASYN'],\n",
        "    ['RFE-CV', 'CLASS WEIGHT'],\n",
        "    ['ADASYN', 'CLASS WEIGHT'],\n",
        "    ['RFE-CV', 'ADASYN', 'CLASS WEIGHT']\n",
        "]\n",
        "\n",
        "all_results = {}\n",
        "for idx, scenario in enumerate(scenarios, start=1):\n",
        "    scenario_name = \" + \".join(scenario) if scenario else \"NO RFE-CV, NO ADASYN, NO CLASS WEIGHT\"\n",
        "    print(f\"Running Scenario {idx}: {scenario_name}\")\n",
        "    results = run_scenario(scenario, df_train,df_test,selected_features,df_train_adasyn,class_weights)\n",
        "    all_results[scenario_name] = results\n",
        "\n",
        "\n",
        "export_all_results(all_results)\n",
        "\n",
        "df_train.info()"
      ],
      "metadata": {
        "id": "2Ioq707sX98d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wp7gIKnOxVRX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}